<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Detection and Transcription</title>
</head>
<body>
    <h1>KYC</h1>
    <video id="videoElement" width="640" height="480" autoplay></video>
    
    <!-- Start and Stop buttons for audio recording -->
    <button id="startButton">Start Listening</button>
    <button id="stopButton" disabled>Stop Listening</button>

    <br><br>
    
    <!-- Display Transcribed Text -->
    <h3>Transcribed Text:</h3>
    <p id="transcription">Waiting for speech...</p>

    <script>
        // DOM Elements
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const videoElement = document.getElementById('videoElement');
        const transcriptionElement = document.getElementById('transcription');

        // Check for SpeechRecognition API
        let speechRecognition;
        let allSpeechWhileRecording = "";
        let consentText = "I GIVE CONSENT TO BE POSP OF LANDMARK";

        if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
            speechRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            speechRecognition.continuous = true;  // Keep recognizing continuously
            speechRecognition.interimResults = true;  // Show partial results

            // Event listener for when speech is recognized
            speechRecognition.onresult = (event) => {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    transcript += event.results[i][0].transcript; // Get the recognized text
                }
                allSpeechWhileRecording += transcript;
                transcriptionElement.textContent = transcript; // Display the transcribed text
            };

            // Handle errors
            speechRecognition.onerror = (event) => {
                console.error('Speech recognition error:', event);
            };
        } else {
            alert("Speech recognition is not supported in this browser.");
        }

        // Start Listening
        startButton.addEventListener('click', async () => {
            try {
                // Access the webcam and microphone (both video and audio)
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });

                // Set the video source and start playing the video
                videoElement.srcObject = stream;

                // Mute the video to avoid video audio interference
                videoElement.muted = true;

                // Start Speech Recognition to capture only the audio from the microphone
                speechRecognition.start();

                // Update UI
                startButton.disabled = true;  // Disable start button
                stopButton.disabled = false;  // Enable stop button
                transcriptionElement.textContent = 'Listening...';  // Show listening message
            } catch (err) {
                console.error('Error accessing media devices:', err);
            }
        });

        // Stop Listening
        stopButton.addEventListener('click', () => {
            speechRecognition.stop(); // Stop recognition
            startButton.disabled = false;  // Enable start button
            stopButton.disabled = true;   // Disable stop button
            transcriptionElement.textContent = 'Stopped listening...'; // Show stopped message
            if (allSpeechWhileRecording.toUpperCase().includes(consentText)) {
                alert(consentText);
            } else {
                console.log(allSpeechWhileRecording);
            }
        });
    </script>
</body>
</html>
